{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(path, threshold:int=0.5):\n",
    "    \n",
    "    simbert_test = json.load(open(path))\n",
    "\n",
    "    sims_np = np.array(simbert_test['sims'])\n",
    "    pred_np = np.asarray(sims_np > threshold, dtype=np.int32)\n",
    "    true_np = np.asarray(simbert_test['label'])\n",
    "    # print(classification_report(true_np, pred_np),accuracy_score(true_np, pred_np), f1_score(true_np, pred_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82       904\n",
      "           1       0.86      0.94      0.89      1377\n",
      "\n",
      "    accuracy                           0.87      2281\n",
      "   macro avg       0.87      0.85      0.86      2281\n",
      "weighted avg       0.87      0.87      0.87      2281\n",
      " 0.8671635247698378 0.8948281846581048\n"
     ]
    }
   ],
   "source": [
    "eval('./tmp_data/supSBERT_RDropout_simbert_batchSize16_test', 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.74      0.79       904\n",
      "           1       0.84      0.92      0.88      1377\n",
      "\n",
      "    accuracy                           0.85      2281\n",
      "   macro avg       0.85      0.83      0.84      2281\n",
      "weighted avg       0.85      0.85      0.85      2281\n",
      " 0.8491889522139413 0.8808864265927977\n"
     ]
    }
   ],
   "source": [
    "eval('./tmp_data/supSBERT_simbert_batchSize32_test', 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81       904\n",
      "           1       0.85      0.92      0.89      1377\n",
      "\n",
      "    accuracy                           0.86      2281\n",
      "   macro avg       0.86      0.84      0.85      2281\n",
      "weighted avg       0.86      0.86      0.86      2281\n",
      " 0.8592722490135906 0.8879581151832461\n"
     ]
    }
   ],
   "source": [
    "eval('./tmp_data/supSBERT_simbert_batchSize128_test', 0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80       976\n",
      "           1       0.85      0.90      0.87      1448\n",
      "\n",
      "    accuracy                           0.84      2424\n",
      "   macro avg       0.84      0.83      0.83      2424\n",
      "weighted avg       0.84      0.84      0.84      2424\n",
      " 0.8428217821782178 0.8718466195761858\n"
     ]
    }
   ],
   "source": [
    "eval('./tmp_data/supSimCSE_batchSize64_roformerSim_test', 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       976\n",
      "           1       0.82      0.90      0.86      1448\n",
      "\n",
      "    accuracy                           0.82      2424\n",
      "   macro avg       0.83      0.80      0.81      2424\n",
      "weighted avg       0.82      0.82      0.82      2424\n",
      " 0.8238448844884488 0.8598621595011487\n"
     ]
    }
   ],
   "source": [
    "eval('./tmp_data/supSimCSE_simbert_batchSize64_test', 0.62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.80      0.62      8662\n",
      "           1       0.72      0.40      0.51     11313\n",
      "\n",
      "    accuracy                           0.57     19975\n",
      "   macro avg       0.61      0.60      0.56     19975\n",
      "weighted avg       0.63      0.57      0.56     19975\n",
      " 0.5706132665832291 0.511365578533584\n"
     ]
    }
   ],
   "source": [
    "eval('./tmp_data/simbert_test', 0.55) # 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.57      0.65      8662\n",
      "           1       0.72      0.87      0.79     11313\n",
      "\n",
      "    accuracy                           0.74     19975\n",
      "   macro avg       0.75      0.72      0.72     19975\n",
      "weighted avg       0.74      0.74      0.73     19975\n",
      " 0.737622027534418 0.7892556998673047\n"
     ]
    }
   ],
   "source": [
    "eval('./tmp_data/simbert_whitening_test', 0.55) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.61      0.67      8662\n",
      "           1       0.74      0.83      0.78     11313\n",
      "\n",
      "    accuracy                           0.74     19975\n",
      "   macro avg       0.74      0.72      0.72     19975\n",
      "weighted avg       0.74      0.74      0.73     19975\n",
      " 0.7367709637046308 0.782151143520053\n"
     ]
    }
   ],
   "source": [
    "eval('./tmp_data/roformer_sim_ft_test', 0.71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.45      0.59      8662\n",
      "           1       0.69      0.94      0.80     11313\n",
      "\n",
      "    accuracy                           0.73     19975\n",
      "   macro avg       0.77      0.70      0.70     19975\n",
      "weighted avg       0.76      0.73      0.71     19975\n",
      " 0.7296620775969962 0.7977073499662846\n"
     ]
    }
   ],
   "source": [
    "eval('./tmp_data/roformer_sim_test', 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.56      0.65      8662\n",
      "           1       0.72      0.87      0.79     11313\n",
      "\n",
      "    accuracy                           0.74     19975\n",
      "   macro avg       0.74      0.71      0.72     19975\n",
      "weighted avg       0.74      0.74      0.73     19975\n",
      " 0.7352690863579474 0.7878350184561066\n"
     ]
    }
   ],
   "source": [
    "eval('./tmp_data/roformer_sim_whitening_test', 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\FAQ_PROJECT\\FAQ project\\check.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000008?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertTokenizer\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000008?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000008?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m util\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000008?line=5'>6</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000008?line=6'>7</a>\u001b[0m pretrained_model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjunnyu/roformer_chinese_sim_char_base\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from roformer import RoFormerForCausalLM, RoFormerConfig\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from .utils import util\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_model = \"junnyu/roformer_chinese_sim_char_base\"\n",
    "tokz = BertTokenizer.from_pretrained(pretrained_model)\n",
    "config = RoFormerConfig.from_pretrained(pretrained_model)\n",
    "config.is_decoder = True\n",
    "config.eos_token_id = tokz.sep_token_id\n",
    "config.pooler_activation = \"linear\"\n",
    "config.output_hidden_states = True\n",
    "roformer_sim = RoFormerForCausalLM.from_pretrained(pretrained_model, config=config)\n",
    "roformer_sim.to(device)\n",
    "roformer_sim.eval()\n",
    "\n",
    "test_iter = util.get_paired_dataIter('./data/merged_qq_test.csv', tokz, device, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(10)\n",
    "isinstance(a, torch.Tensor)\n",
    "np.clip(a, 1e-8, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((3,4))\n",
    "b = np.zeros((2,4))\n",
    "l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.extend(a.flatten())\n",
    "l.extend(b.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([a,b],axis=0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.randn((4,4,))\n",
    "eye_mask = torch.eye((4)) * -1e12\n",
    "d = eye_mask + c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3248, 0.2401, 0.4351],\n",
       "        [0.5171, 0.0000, 0.3862, 0.0967],\n",
       "        [0.5216, 0.0608, 0.0000, 0.4176],\n",
       "        [0.2576, 0.1257, 0.6168, 0.0000]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(d, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "loss = CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0,1,0,0], [1,0,0,0],[0,0,0,1],[0,0,1,0]])\n",
    "\n",
    "[1, 0, 3, 2]\n",
    "\n",
    "t = torch.arange(4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3, 2])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.hstack([ti for t1_t2 in zip(t[1::2], t[0::2]) for ti in t1_t2])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3248, 0.2401, 0.4351],\n",
       "        [0.5171, 0.0000, 0.3862, 0.0967],\n",
       "        [0.5216, 0.0608, 0.0000, 0.4176],\n",
       "        [0.2576, 0.1257, 0.6168, 0.0000]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba = torch.nn.functional.softmax(d, dim=1)\n",
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False, False],\n",
       "        [ True, False, False, False],\n",
       "        [False, False, False,  True],\n",
       "        [False, False,  True, False]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = labels[:, None] == torch.arange(4)[None, :]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1247, -0.6595, -0.8732, -0.4832])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba[index].log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1247, 0.6595, 0.8732, 0.4832])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(d, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchSize=3\n",
    "seqLen=5\n",
    "hidden_nums=4\n",
    "a = torch.ones(batchSize,hidden_nums)\n",
    "b = torch.zeros(batchSize,hidden_nums)\n",
    "a_and_b = torch.concat([a,b], dim=-1)\n",
    "a_and_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 + torch.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_and_b.view(batchSize*2, hidden_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_and_b.view(4,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. simCSE \n",
    "## 1.1 simCSE + whitening(368)\n",
    "# 2. supervised\n",
    "## 2.1 SBERT \n",
    "## 2.2 SBERT + R-dropout(监督)\n",
    "## 2.3 SBERT + Info-NCE(多个neg_sample)\n",
    "## 2.4 SBERT + R-dropout + Info-NCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = a.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4., 4.],\n",
       "        [4., 4., 4.],\n",
       "        [4., 4., 4.]], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a_gpu, a_gpu.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to(a_gpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 6, 3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.w = nn.Parameter(torch.randn(2,1))\n",
    "        self.b = nn.Parameter(torch.zeros(1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x@self.w + self.b\n",
    "        return y\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('../data/tensorboard')\n",
    "writer.add_graph(net,input_to_model = torch.ones(10,2))\n",
    "writer.add_graph(net,input_to_model = torch.ones(10,2))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "#%tensorboard --logdir ../data/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir ../data/tensorboard (started 0:03:19 ago; pid 1060)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1060), started 0:03:20 ago. (Use '!kill 1060' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a6571c5dceac65f1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a6571c5dceac65f1\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#在tensorboard中查看模型\n",
    "notebook.start(\"--logdir ../data/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "w = torch.tensor([[3.0,1.0]],requires_grad=True)\n",
    "b = torch.tensor([[3.0]],requires_grad=True)\n",
    "X = torch.randn(10,2)\n",
    "Y = torch.randn(10,1)\n",
    "Y_hat = X@w.t() + b  # Y_hat定义后其正向传播被立即执行，与其后面的loss创建语句无关\n",
    "Y_hat.retain_grad()\n",
    "loss = torch.mean(torch.pow(Y_hat-Y,2))\n",
    "\n",
    "#计算图在反向传播后立即销毁，如果需要保留计算图, 需要设置retain_graph = True\n",
    "loss.backward()  \n",
    "# loss.backward(retain_graph = True) \n",
    "# loss.backward() #如果再次执行反向传播将报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先尝试一下forward拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(1)\n",
    "b = torch.full(size=(1,), fill_value=2., requires_grad=True)\n",
    "\n",
    "a_and_b = torch.concat([a,b], dim=0)\n",
    "a_and_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4.], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = a_and_b ** 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.]), None)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad, a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.ones(1, requires_grad=True)\n",
    "y = k ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "d:\\conda\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import BertConfig, BertModel, BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "\n",
    "def L2_norm(vecs):\n",
    "\n",
    "    if isinstance(vecs, torch.Tensor):\n",
    "        norms = (vecs**2).sum(dim=1, keepdims=True).sqrt()\n",
    "        return vecs / torch.clamp(norms, 1e-8, )\n",
    "    elif isinstance(vecs, np.ndarray):\n",
    "        norms = (vecs**2).sum(axis=1, keepdims=True)**0.5\n",
    "        return vecs / np.clip(norms, 1e-8, np.inf)\n",
    "\n",
    "class SimCSELoss1(nn.CrossEntropyLoss):\n",
    "\n",
    "    def _create_sim_labels(self, sents_vecs):\n",
    "\n",
    "        sample_nums = sents_vecs.shape[0]   # sample_nums = batchSize * 2\n",
    "        idxs = torch.arange(sample_nums)\n",
    "        labels = torch.hstack([i for i1_i2 in zip(idxs[1::2], idxs[::2]) for i in i1_i2])\n",
    "        labels = labels.to(sents_vecs.device)\n",
    "        \n",
    "        return labels\n",
    "\n",
    "    def _cal_masked_sent_sims(self, sents_vecs):\n",
    "\n",
    "        sents_vecs = L2_norm(sents_vecs) # (batchSize*2, hidden_nums)\n",
    "        sents_sims = torch.matmul(sents_vecs, sents_vecs.T) \n",
    "\n",
    "        sample_nums = sents_sims.shape[0]\n",
    "        eye_mask = torch.eye(sample_nums) * -1e12\n",
    "        eye_mask = eye_mask.to(sents_sims.device)\n",
    "        masked_sents_sims = sents_sims + eye_mask\n",
    "\n",
    "        return masked_sents_sims\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        sents_vecs:torch.Tensor,\n",
    "        reduction:int = 'mean',\n",
    "    ):\n",
    "        '''\n",
    "        sents_vecs: (batchSize*2, hidden_nums)\n",
    "\n",
    "        - Detailed:\n",
    "            - s_{2j=1} and s_{2j} are the similar ones\n",
    "        '''\n",
    "\n",
    "        masked_sents_sims = self._cal_masked_sent_sims(sents_vecs) # (batchSize*2, hidden_nums)\n",
    "        labels = self._create_sim_labels(sents_vecs) # (batchSize*2, ) [constractive learning]\n",
    "        self.reduction = reduction\n",
    "        loss = super(SimCSELoss1, self).forward(masked_sents_sims, labels)\n",
    "        return loss\n",
    "\n",
    "class SimCSELoss2(nn.CrossEntropyLoss):\n",
    "\n",
    "    def _create_sim_labels(self, sents_vecs):\n",
    "\n",
    "        sample_nums = sents_vecs.shape[0]   # sample_nums = batchSize * 2\n",
    "        idxs = torch.arange(sample_nums)\n",
    "        labels = torch.hstack([i for i1_i2 in zip(idxs[1::2], idxs[::2]) for i in i1_i2])\n",
    "        labels = labels.to(sents_vecs.device)\n",
    "        return labels\n",
    "\n",
    "    def _cal_masked_sent_sims(self, sub_sents_vecs, sents_vecs):\n",
    "        '''\n",
    "        :@param sub_sents_vecs: (subSampleSize, hidden_nums)\n",
    "        :@param sents_vecs: (batchSize*2 | sampleSize, hidden_nums)\n",
    "\n",
    "        Return:\n",
    "        sub_masked_sents_sims: (subSampleSize, hidden_nums)\n",
    "        '''\n",
    "        \n",
    "        sub_sents_sims = torch.matmul(sub_sents_vecs, sents_vecs.T) \n",
    "        sub_sample_size, batch_size = sub_sents_sims.shape\n",
    "        \n",
    "        eye_mask = torch.eye(sub_sample_size) * -1e12   #(subSampleSize, subSampleSize)\n",
    "        mask = torch.concat([eye_mask, torch.zeros((sub_sample_size, (batch_size - sub_sample_size)))], dim=1)  #(subSampleSize, batchSize)\n",
    "        mask = mask.to(sub_sents_sims.device)\n",
    "\n",
    "        sub_masked_sents_sims = sub_sents_sims + mask\n",
    "        return sub_masked_sents_sims\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        sents_vecs:torch.Tensor,\n",
    "        batch_split:int = 2,\n",
    "        reduction:str = 'none',\n",
    "    ):\n",
    "        '''\n",
    "        sents_vecs: (batchSize*2, hidden_nums)\n",
    "\n",
    "        - Detailed:\n",
    "            - s_{2j=1} and s_{2j} are the similar ones\n",
    "        '''\n",
    "        self.reduction = 'none'\n",
    "        sample_size = sents_vecs.shape[0]   # sample_size == batchSize * 2\n",
    "        print(sample_size)\n",
    "        assert (sample_size % batch_split == 0) and (sample_size // batch_split % 2 ==0)    \n",
    "        # sents_vecs could be deviced into each part with the same number in it\n",
    "        # In each part, the number of sample sould even rather odd\n",
    "        \n",
    "        tot_labels = self._create_sim_labels(sents_vecs)    # (batchSize, )\n",
    "        sents_vecs = L2_norm(sents_vecs)   # (batchSize*2, hidden_nums)\n",
    "\n",
    "        loss = []\n",
    "        for i in range(0, sample_size, batch_split):\n",
    "            start = int(i)\n",
    "            end = int(i+batch_split)\n",
    "            sub_sents_vecs = sents_vecs[start:end]\n",
    "            sub_masked_sent_sims = self._cal_masked_sent_sims(sub_sents_vecs, sents_vecs)   #(subSampleSize, batchSize)\n",
    "            sub_labels = tot_labels[start:end]    #(subSampleSize, )\n",
    "            sub_loss = super(SimCSELoss2, self).forward(sub_masked_sent_sims, sub_labels)   # (subSampleSize, )\n",
    "            loss.append(sub_loss)\n",
    "\n",
    "        assert end == sample_size\n",
    "\n",
    "        loss = torch.concat(loss, dim=0)\n",
    "        if reduction == 'none':\n",
    "            return loss\n",
    "        elif reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            return loss.sum()\n",
    "\n",
    "class SimCSELoss(nn.CrossEntropyLoss):\n",
    "\n",
    "    def _create_sim_labels(self, sents_vecs):\n",
    "\n",
    "        sample_nums = sents_vecs.shape[0]   # sample_nums = batchSize * 2\n",
    "        idxs = torch.arange(sample_nums)\n",
    "        labels = torch.hstack([i for i1_i2 in zip(idxs[1::2], idxs[::2]) for i in i1_i2])\n",
    "        labels = labels.to(sents_vecs.device)\n",
    "        return labels\n",
    "\n",
    "    def _cal_masked_sent_sims(self, sub_sents_vecs, sents_vecs):\n",
    "        '''\n",
    "        :@param sub_sents_vecs: (subSampleSize, hidden_nums)\n",
    "        :@param sents_vecs: (batchSize*2 | sampleSize, hidden_nums)\n",
    "\n",
    "        Return:\n",
    "        sub_masked_sents_sims: (subSampleSize, hidden_nums)\n",
    "        '''\n",
    "        \n",
    "        sub_sents_sims = torch.matmul(sub_sents_vecs, sents_vecs.T) \n",
    "        sub_sample_size, batch_size = sub_sents_sims.shape\n",
    "        \n",
    "        eye_mask = torch.eye(sub_sample_size) * -1e12   #(subSampleSize, subSampleSize)\n",
    "        mask = torch.concat([eye_mask, torch.zeros((sub_sample_size, (batch_size - sub_sample_size)))], dim=1)  #(subSampleSize, batchSize)\n",
    "        mask = mask.to(sub_sents_sims.device)\n",
    "\n",
    "        sub_masked_sents_sims = sub_sents_sims + mask\n",
    "        return sub_masked_sents_sims\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        start:int,\n",
    "        end:int,\n",
    "        sents_vecs:torch.Tensor,\n",
    "        batch_split:int = 2,\n",
    "        reduction:str = 'none',\n",
    "    ):\n",
    "        '''\n",
    "        sents_vecs: (batchSize*2, hidden_nums)\n",
    "\n",
    "        - Detailed:\n",
    "            - s_{2j=1} and s_{2j} are the similar ones\n",
    "        '''\n",
    "        self.reduction = 'none'\n",
    "        tot_labels = self._create_sim_labels(sents_vecs)    # (batchSize, )\n",
    "        sents_vecs = L2_norm(sents_vecs)   # (batchSize*2, hidden_nums)\n",
    "\n",
    "        sub_sents_vecs = sents_vecs[start:end, :]\n",
    "        sub_labels = tot_labels[start:end]\n",
    "\n",
    "        sub_masked_sent_sims = self._cal_masked_sent_sims(sub_sents_vecs, sents_vecs) \n",
    "        sub_loss = super(SimCSELoss, self).forward(sub_masked_sent_sims, sub_labels)\n",
    "\n",
    "        if reduction == 'none':\n",
    "            return sub_loss\n",
    "        elif reduction == 'mean':\n",
    "            return sub_loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            return sub_loss.sum()\n",
    "\n",
    "tokz = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "optimizer = AdamW(bert.parameters(), lr=1e-5)\n",
    "criterion = SimCSELoss1()\n",
    "bert.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch #: 0\n",
      "0\n",
      "epoch #: 1\n",
      "0\n",
      "epoch #: 2\n",
      "0\n",
      "epoch #: 3\n",
      "0\n",
      "epoch #: 4\n",
      "0\n",
      "epoch #: 5\n",
      "0\n",
      "epoch #: 6\n",
      "0\n",
      "epoch #: 7\n",
      "0\n",
      "epoch #: 8\n",
      "0\n",
      "epoch #: 9\n",
      "0\n",
      "epoch #: 10\n",
      "0\n",
      "epoch #: 11\n",
      "0\n",
      "epoch #: 12\n",
      "0\n",
      "epoch #: 13\n",
      "0\n",
      "epoch #: 14\n",
      "0\n",
      "epoch #: 15\n",
      "0\n",
      "epoch #: 16\n",
      "0\n",
      "epoch #: 17\n",
      "0\n",
      "epoch #: 18\n",
      "0\n",
      "epoch #: 19\n",
      "0\n",
      "epoch #: 20\n",
      "0\n",
      "epoch #: 21\n",
      "0\n",
      "epoch #: 22\n",
      "0\n",
      "epoch #: 23\n",
      "0\n",
      "epoch #: 24\n",
      "0\n",
      "epoch #: 25\n",
      "0\n",
      "epoch #: 26\n",
      "0\n",
      "epoch #: 27\n",
      "0\n",
      "epoch #: 28\n",
      "0\n",
      "epoch #: 29\n",
      "0\n",
      "epoch #: 30\n",
      "0\n",
      "epoch #: 31\n",
      "0\n",
      "epoch #: 32\n",
      "0\n",
      "epoch #: 33\n",
      "0\n",
      "epoch #: 34\n",
      "0\n",
      "epoch #: 35\n",
      "0\n",
      "epoch #: 36\n",
      "0\n",
      "epoch #: 37\n",
      "0\n",
      "epoch #: 38\n",
      "0\n",
      "epoch #: 39\n",
      "0\n",
      "epoch #: 40\n",
      "0\n",
      "epoch #: 41\n",
      "0\n",
      "epoch #: 42\n",
      "0\n",
      "epoch #: 43\n",
      "0\n",
      "epoch #: 44\n",
      "0\n",
      "epoch #: 45\n",
      "0\n",
      "epoch #: 46\n",
      "0\n",
      "epoch #: 47\n",
      "0\n",
      "epoch #: 48\n",
      "0\n",
      "epoch #: 49\n",
      "0\n",
      "epoch #: 50\n",
      "0\n",
      "epoch #: 51\n",
      "0\n",
      "epoch #: 52\n",
      "0\n",
      "epoch #: 53\n",
      "0\n",
      "epoch #: 54\n",
      "0\n",
      "epoch #: 55\n",
      "0\n",
      "epoch #: 56\n",
      "0\n",
      "epoch #: 57\n",
      "0\n",
      "epoch #: 58\n",
      "0\n",
      "epoch #: 59\n",
      "0\n",
      "epoch #: 60\n",
      "0\n",
      "epoch #: 61\n",
      "0\n",
      "epoch #: 62\n",
      "0\n",
      "epoch #: 63\n",
      "0\n",
      "epoch #: 64\n",
      "0\n",
      "epoch #: 65\n",
      "0\n",
      "epoch #: 66\n",
      "0\n",
      "epoch #: 67\n",
      "0\n",
      "epoch #: 68\n",
      "0\n",
      "epoch #: 69\n",
      "0\n",
      "epoch #: 70\n",
      "0\n",
      "epoch #: 71\n",
      "0\n",
      "epoch #: 72\n",
      "0\n",
      "epoch #: 73\n",
      "0\n",
      "epoch #: 74\n",
      "0\n",
      "epoch #: 75\n",
      "0\n",
      "epoch #: 76\n",
      "0\n",
      "epoch #: 77\n",
      "0\n",
      "epoch #: 78\n",
      "0\n",
      "epoch #: 79\n",
      "0\n",
      "epoch #: 80\n",
      "0\n",
      "epoch #: 81\n",
      "0\n",
      "epoch #: 82\n",
      "0\n",
      "epoch #: 83\n",
      "0\n",
      "epoch #: 84\n",
      "0\n",
      "epoch #: 85\n",
      "0\n",
      "epoch #: 86\n",
      "0\n",
      "epoch #: 87\n",
      "0\n",
      "epoch #: 88\n",
      "0\n",
      "epoch #: 89\n",
      "0\n",
      "epoch #: 90\n",
      "0\n",
      "epoch #: 91\n",
      "0\n",
      "epoch #: 92\n",
      "0\n",
      "epoch #: 93\n",
      "0\n",
      "epoch #: 94\n",
      "0\n",
      "epoch #: 95\n",
      "0\n",
      "epoch #: 96\n",
      "0\n",
      "epoch #: 97\n",
      "0\n",
      "epoch #: 98\n",
      "0\n",
      "epoch #: 99\n",
      "0\n",
      "epoch #: 100\n",
      "0\n",
      "epoch #: 101\n",
      "0\n",
      "epoch #: 102\n",
      "0\n",
      "epoch #: 103\n",
      "0\n",
      "epoch #: 104\n",
      "0\n",
      "epoch #: 105\n",
      "0\n",
      "epoch #: 106\n",
      "0\n",
      "epoch #: 107\n",
      "0\n",
      "epoch #: 108\n",
      "0\n",
      "epoch #: 109\n",
      "0\n",
      "epoch #: 110\n",
      "0\n",
      "epoch #: 111\n",
      "0\n",
      "epoch #: 112\n",
      "0\n",
      "epoch #: 113\n",
      "0\n",
      "epoch #: 114\n",
      "0\n",
      "epoch #: 115\n",
      "0\n",
      "epoch #: 116\n",
      "0\n",
      "epoch #: 117\n",
      "0\n",
      "epoch #: 118\n",
      "0\n",
      "epoch #: 119\n",
      "0\n",
      "epoch #: 120\n",
      "0\n",
      "epoch #: 121\n",
      "0\n",
      "epoch #: 122\n",
      "0\n",
      "epoch #: 123\n",
      "0\n",
      "epoch #: 124\n",
      "0\n",
      "epoch #: 125\n",
      "0\n",
      "epoch #: 126\n",
      "0\n",
      "epoch #: 127\n",
      "0\n",
      "epoch #: 128\n",
      "0\n",
      "epoch #: 129\n",
      "0\n",
      "epoch #: 130\n",
      "0\n",
      "epoch #: 131\n",
      "0\n",
      "epoch #: 132\n",
      "0\n",
      "epoch #: 133\n",
      "0\n",
      "epoch #: 134\n",
      "0\n",
      "epoch #: 135\n",
      "0\n",
      "epoch #: 136\n",
      "0\n",
      "epoch #: 137\n",
      "0\n",
      "epoch #: 138\n",
      "0\n",
      "epoch #: 139\n",
      "0\n",
      "epoch #: 140\n",
      "0\n",
      "epoch #: 141\n",
      "0\n",
      "epoch #: 142\n",
      "0\n",
      "epoch #: 143\n",
      "0\n",
      "epoch #: 144\n",
      "0\n",
      "epoch #: 145\n",
      "0\n",
      "epoch #: 146\n",
      "0\n",
      "epoch #: 147\n",
      "0\n",
      "epoch #: 148\n",
      "0\n",
      "epoch #: 149\n",
      "0\n",
      "epoch #: 150\n",
      "0\n",
      "epoch #: 151\n",
      "0\n",
      "epoch #: 152\n",
      "0\n",
      "epoch #: 153\n",
      "0\n",
      "epoch #: 154\n",
      "0\n",
      "epoch #: 155\n",
      "0\n",
      "epoch #: 156\n",
      "0\n",
      "epoch #: 157\n",
      "0\n",
      "epoch #: 158\n",
      "0\n",
      "epoch #: 159\n",
      "0\n",
      "epoch #: 160\n",
      "0\n",
      "epoch #: 161\n",
      "0\n",
      "epoch #: 162\n",
      "0\n",
      "epoch #: 163\n",
      "0\n",
      "epoch #: 164\n",
      "0\n",
      "epoch #: 165\n",
      "0\n",
      "epoch #: 166\n",
      "0\n",
      "epoch #: 167\n",
      "0\n",
      "epoch #: 168\n",
      "0\n",
      "epoch #: 169\n",
      "0\n",
      "epoch #: 170\n",
      "0\n",
      "epoch #: 171\n",
      "0\n",
      "epoch #: 172\n",
      "0\n",
      "epoch #: 173\n",
      "0\n",
      "epoch #: 174\n",
      "0\n",
      "epoch #: 175\n",
      "0\n",
      "epoch #: 176\n",
      "0\n",
      "epoch #: 177\n",
      "0\n",
      "epoch #: 178\n",
      "0\n",
      "epoch #: 179\n",
      "0\n",
      "epoch #: 180\n",
      "0\n",
      "epoch #: 181\n",
      "0\n",
      "epoch #: 182\n",
      "0\n",
      "epoch #: 183\n",
      "0\n",
      "epoch #: 184\n",
      "0\n",
      "epoch #: 185\n",
      "0\n",
      "epoch #: 186\n",
      "0\n",
      "epoch #: 187\n",
      "0\n",
      "epoch #: 188\n",
      "0\n",
      "epoch #: 189\n",
      "0\n",
      "epoch #: 190\n",
      "0\n",
      "epoch #: 191\n",
      "0\n",
      "epoch #: 192\n",
      "0\n",
      "epoch #: 193\n",
      "0\n",
      "epoch #: 194\n",
      "0\n",
      "epoch #: 195\n",
      "0\n",
      "epoch #: 196\n",
      "0\n",
      "epoch #: 197\n",
      "0\n",
      "epoch #: 198\n",
      "0\n",
      "epoch #: 199\n",
      "0\n",
      "epoch #: 200\n",
      "0\n",
      "epoch #: 201\n",
      "0\n",
      "epoch #: 202\n",
      "0\n",
      "epoch #: 203\n",
      "0\n",
      "epoch #: 204\n",
      "0\n",
      "epoch #: 205\n",
      "0\n",
      "epoch #: 206\n",
      "0\n",
      "epoch #: 207\n",
      "0\n",
      "epoch #: 208\n",
      "0\n",
      "epoch #: 209\n",
      "0\n",
      "epoch #: 210\n",
      "0\n",
      "epoch #: 211\n",
      "0\n",
      "epoch #: 212\n",
      "0\n",
      "epoch #: 213\n",
      "0\n",
      "epoch #: 214\n",
      "0\n",
      "epoch #: 215\n",
      "0\n",
      "epoch #: 216\n",
      "0\n",
      "epoch #: 217\n",
      "0\n",
      "epoch #: 218\n",
      "0\n",
      "epoch #: 219\n",
      "0\n",
      "epoch #: 220\n",
      "0\n",
      "epoch #: 221\n",
      "0\n",
      "epoch #: 222\n",
      "0\n",
      "epoch #: 223\n",
      "0\n",
      "epoch #: 224\n",
      "0\n",
      "epoch #: 225\n",
      "0\n",
      "epoch #: 226\n",
      "0\n",
      "epoch #: 227\n",
      "0\n",
      "epoch #: 228\n",
      "0\n",
      "epoch #: 229\n",
      "0\n",
      "epoch #: 230\n",
      "0\n",
      "epoch #: 231\n",
      "0\n",
      "epoch #: 232\n",
      "0\n",
      "epoch #: 233\n",
      "0\n",
      "epoch #: 234\n",
      "0\n",
      "epoch #: 235\n",
      "0\n",
      "epoch #: 236\n",
      "0\n",
      "epoch #: 237\n",
      "0\n",
      "epoch #: 238\n",
      "0\n",
      "epoch #: 239\n",
      "0\n",
      "epoch #: 240\n",
      "0\n",
      "epoch #: 241\n",
      "0\n",
      "epoch #: 242\n",
      "0\n",
      "epoch #: 243\n",
      "0\n",
      "epoch #: 244\n",
      "0\n",
      "epoch #: 245\n",
      "0\n",
      "epoch #: 246\n",
      "0\n",
      "epoch #: 247\n",
      "0\n",
      "epoch #: 248\n",
      "0\n",
      "epoch #: 249\n",
      "0\n",
      "epoch #: 250\n",
      "0\n",
      "epoch #: 251\n",
      "0\n",
      "epoch #: 252\n",
      "0\n",
      "epoch #: 253\n",
      "0\n",
      "epoch #: 254\n",
      "0\n",
      "epoch #: 255\n",
      "0\n",
      "epoch #: 256\n",
      "0\n",
      "epoch #: 257\n",
      "0\n",
      "epoch #: 258\n",
      "0\n",
      "epoch #: 259\n",
      "0\n",
      "epoch #: 260\n",
      "0\n",
      "epoch #: 261\n",
      "0\n",
      "epoch #: 262\n",
      "0\n",
      "epoch #: 263\n",
      "0\n",
      "epoch #: 264\n",
      "0\n",
      "epoch #: 265\n",
      "0\n",
      "epoch #: 266\n",
      "0\n",
      "epoch #: 267\n",
      "0\n",
      "epoch #: 268\n",
      "0\n",
      "epoch #: 269\n",
      "0\n",
      "epoch #: 270\n",
      "0\n",
      "epoch #: 271\n",
      "0\n",
      "epoch #: 272\n",
      "0\n",
      "epoch #: 273\n",
      "0\n",
      "epoch #: 274\n",
      "0\n",
      "epoch #: 275\n",
      "0\n",
      "epoch #: 276\n",
      "0\n",
      "epoch #: 277\n",
      "0\n",
      "epoch #: 278\n",
      "0\n",
      "epoch #: 279\n",
      "0\n",
      "epoch #: 280\n",
      "0\n",
      "epoch #: 281\n",
      "0\n",
      "epoch #: 282\n",
      "0\n",
      "epoch #: 283\n",
      "0\n",
      "epoch #: 284\n",
      "0\n",
      "epoch #: 285\n",
      "0\n",
      "epoch #: 286\n",
      "0\n",
      "epoch #: 287\n",
      "0\n",
      "epoch #: 288\n",
      "0\n",
      "epoch #: 289\n",
      "0\n",
      "epoch #: 290\n",
      "0\n",
      "epoch #: 291\n",
      "0\n",
      "epoch #: 292\n",
      "0\n",
      "epoch #: 293\n",
      "0\n",
      "epoch #: 294\n",
      "0\n",
      "epoch #: 295\n",
      "0\n",
      "epoch #: 296\n",
      "0\n",
      "epoch #: 297\n",
      "0\n",
      "epoch #: 298\n",
      "0\n",
      "epoch #: 299\n"
     ]
    }
   ],
   "source": [
    "batchSize = 32\n",
    "for i in range(300):\n",
    "    concat_output = []\n",
    "    concat_sent1 = []\n",
    "    concat_sent2 = []\n",
    "    for _ in range(1):\n",
    "        text = '我就是来测试一下，不会带有什么目的，纯粹的测试文档'\n",
    "        texts = [text[:] for _ in range(batchSize)]\n",
    "        batchData = tokz(texts, padding=True, return_tensors='pt').to(bert.device)\n",
    "\n",
    "        sent_vecs_1 = bert(**batchData).pooler_output\n",
    "        sent_vecs_2 = bert(**batchData).pooler_output\n",
    "\n",
    "        concat_sent1.append(sent_vecs_1)\n",
    "        concat_sent2.append(sent_vecs_2)\n",
    "\n",
    "        print(_)\n",
    "    concat_sent1 = torch.concat(concat_sent1, dim=0)\n",
    "    concat_sent2 = torch.concat(concat_sent2, dim=0)\n",
    "\n",
    "    batchSize, hidden_nums = concat_sent1.shape\n",
    "    combined_sent_vecs = torch.concat([concat_sent1, concat_sent2], dim=-1) # (batchSize, hidden_nums*2)\n",
    "    combined_sent_vecs = combined_sent_vecs.view(batchSize*2, hidden_nums) # (batchSize*2, hidden_nums)\n",
    "\n",
    "    loss = criterion(combined_sent_vecs,reduction='mean')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f'epoch #: {i}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #: 0\n",
      "epoch #: 1\n",
      "epoch #: 2\n",
      "epoch #: 3\n",
      "epoch #: 4\n",
      "epoch #: 5\n",
      "epoch #: 6\n",
      "epoch #: 7\n",
      "epoch #: 8\n",
      "epoch #: 9\n",
      "epoch #: 10\n",
      "epoch #: 11\n",
      "epoch #: 12\n",
      "epoch #: 13\n",
      "epoch #: 14\n",
      "epoch #: 15\n",
      "epoch #: 16\n",
      "epoch #: 17\n",
      "epoch #: 18\n",
      "epoch #: 19\n",
      "epoch #: 20\n",
      "epoch #: 21\n",
      "epoch #: 22\n",
      "epoch #: 23\n",
      "epoch #: 24\n",
      "epoch #: 25\n",
      "epoch #: 26\n",
      "epoch #: 27\n",
      "epoch #: 28\n",
      "epoch #: 29\n",
      "epoch #: 30\n",
      "epoch #: 31\n",
      "epoch #: 32\n",
      "epoch #: 33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\FAQ_PROJECT\\FAQ project\\check.ipynb Cell 48\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000051?line=3'>4</a>\u001b[0m texts \u001b[39m=\u001b[39m [text[:] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batchSize)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000051?line=4'>5</a>\u001b[0m batchData \u001b[39m=\u001b[39m tokz(texts, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto(bert\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000051?line=6'>7</a>\u001b[0m sent_vecs_1 \u001b[39m=\u001b[39m bert(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatchData)\u001b[39m.\u001b[39mpooler_output\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000051?line=7'>8</a>\u001b[0m sent_vecs_2 \u001b[39m=\u001b[39m bert(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatchData)\u001b[39m.\u001b[39mpooler_output\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000051?line=9'>10</a>\u001b[0m batchSize, hidden_nums \u001b[39m=\u001b[39m sent_vecs_1\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32md:\\conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\conda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:969\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    965\u001b[0m         token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m    967\u001b[0m \u001b[39m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[39m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m extended_attention_mask: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_extended_attention_mask(attention_mask, input_shape, device)\n\u001b[0;32m    971\u001b[0m \u001b[39m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[39m# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_decoder \u001b[39mand\u001b[39;00m encoder_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\conda\\lib\\site-packages\\transformers\\modeling_utils.py:581\u001b[0m, in \u001b[0;36mModuleUtilsMixin.get_extended_attention_mask\u001b[1;34m(self, attention_mask, input_shape, device)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    573\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWrong shape for input_ids (shape \u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m) or attention_mask (shape \u001b[39m\u001b[39m{\u001b[39;00mattention_mask\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m     )\n\u001b[0;32m    576\u001b[0m \u001b[39m# Since attention_mask is 1.0 for positions we want to attend and 0.0 for\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[39m# masked positions, this operation will create a tensor which is 0.0 for\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[39m# positions we want to attend and -10000.0 for masked positions.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[39m# Since we are adding it to the raw scores before the softmax, this is\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \u001b[39m# effectively the same as removing these entirely.\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m extended_attention_mask \u001b[39m=\u001b[39m extended_attention_mask\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)  \u001b[39m# fp16 compatibility\u001b[39;00m\n\u001b[0;32m    582\u001b[0m extended_attention_mask \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m extended_attention_mask) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m10000.0\u001b[39m\n\u001b[0;32m    583\u001b[0m \u001b[39mreturn\u001b[39;00m extended_attention_mask\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(300):\n",
    "    batchSize = 64\n",
    "    text = '我就是来测试一下，不会带有什么目的，纯粹的测试文档'\n",
    "    texts = [text[:] for _ in range(batchSize)]\n",
    "    batchData = tokz(texts, padding=True, return_tensors='pt').to(bert.device)\n",
    "\n",
    "    sent_vecs_1 = bert(**batchData).pooler_output\n",
    "    sent_vecs_2 = bert(**batchData).pooler_output\n",
    "\n",
    "    batchSize, hidden_nums = sent_vecs_1.shape\n",
    "    combined_sent_vecs = torch.concat([sent_vecs_1, sent_vecs_2], dim=-1) # (batchSize, hidden_nums*2)\n",
    "    combined_sent_vecs = combined_sent_vecs.view(batchSize*2, hidden_nums) # (batchSize*2, hidden_nums)\n",
    "    loss = criterion(combined_sent_vecs)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f'epoch #: {_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\FAQ_PROJECT\\FAQ project\\check.ipynb Cell 49\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000062?line=3'>4</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m我就是来测试一下，不会带有什么目的，纯粹的测试文档\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000062?line=4'>5</a>\u001b[0m texts \u001b[39m=\u001b[39m [text[:] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batchSize)]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000062?line=5'>6</a>\u001b[0m batchData \u001b[39m=\u001b[39m tokz(texts, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto(bert\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000062?line=7'>8</a>\u001b[0m sent_vecs_1 \u001b[39m=\u001b[39m bert(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatchData)\u001b[39m.\u001b[39mpooler_output\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FAQ_PROJECT/FAQ%20project/check.ipynb#ch0000062?line=8'>9</a>\u001b[0m sent_vecs_2 \u001b[39m=\u001b[39m bert(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatchData)\u001b[39m.\u001b[39mpooler_output\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokz' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SPLIT = 4\n",
    "for _ in range(300):\n",
    "    batchSize = 60\n",
    "    text = '我就是来测试一下，不会带有什么目的，纯粹的测试文档'\n",
    "    texts = [text[:] for _ in range(batchSize)]\n",
    "    batchData = tokz(texts, padding=True, return_tensors='pt').to(bert.device)\n",
    "\n",
    "    sent_vecs_1 = bert(**batchData).pooler_output\n",
    "    sent_vecs_2 = bert(**batchData).pooler_output\n",
    "\n",
    "    batchSize, hidden_nums = sent_vecs_1.shape\n",
    "    combined_sent_vecs = torch.concat([sent_vecs_1, sent_vecs_2], dim=-1) # (batchSize, hidden_nums*2)\n",
    "    combined_sent_vecs = combined_sent_vecs.view(batchSize*2, hidden_nums) # (batchSize*2, hidden_nums)\n",
    "\n",
    "    sample_size = combined_sent_vecs.shape[0] # sample_size = batchSize * 2\n",
    "    assert sample_size % BATCH_SPLIT == 0\n",
    "    sub_sample_size = sample_size // BATCH_SPLIT   # sub_sample_size: the size of samples in each part\n",
    "\n",
    "    for i in range(0, sample_size, sub_sample_size):\n",
    "        print(i // sub_sample_size)\n",
    "        start = i\n",
    "        end = i + sub_sample_size\n",
    "        # sub_combined_sent_vecs = combined_sent_vecs[start:end, :]   # (sub_sample_size, hidden_nums)\n",
    "        avg_sub_loss = criterion(start, end, combined_sent_vecs.clone(), reduction='mean')\n",
    "        # print(avg_sub_loss)\n",
    "        avg_sub_loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f'epoch #: {_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'loss_module' from 'd:\\\\FAQ_PROJECT\\\\FAQ project\\\\loss_module\\\\__init__.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bert(**batchData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\FAQ_PROJECT\\\\FAQ project'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "simbert = BertModel.from_pretrained('./tmp_data/model_checkpoint/simbert_SimCSE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokz = BertTokenizer.from_pretrained('WangZeJun/simbert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8640"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 检查代码，是否loss中有错误的计算\n",
    "# 2. 如果没问题，尝试将代码上传到云端计算\n",
    "# 3. 使用supervised simcse\n",
    "# 4. 使用supervised sbert (+R-dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [0., 0.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [1., 1.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3,2)\n",
    "b = torch.zeros(3,2)\n",
    "\n",
    "a_and_b = torch.concat([a,b],dim=-1)\n",
    "print(a_and_b)\n",
    "a_and_b.view(6, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3, 4],\n",
       "         [5, 6, 7, 8, 9]]),\n",
       " tensor([4, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(10)\n",
    "a.view(2,5), a.view(2,5).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat(l,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a=1, *args,**kwargs):\n",
    "    print(args)\n",
    "    print(kwargs)\n",
    "    print(a)\n",
    "\n",
    "def extend(func):\n",
    "\n",
    "    class extend:\n",
    "\n",
    "        def __init__(self, *args, **Kwargs):\n",
    "            self.k = 100\n",
    "            pass\n",
    "\n",
    "        def test_sth(self, *args, **kwargs):\n",
    "            func(*args, **kwargs)\n",
    "    return extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = extend(test)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11,)\n",
      "{'b': 1}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "g.test_sth(10, 11, b=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,3, (5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss._Loss"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.modules.loss._Loss\n",
    "# kldiv和nllloss中的Input都是logSoftmax(logits)处理后的数据，也就是输入都是log_probability; 而不是直接输入的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2., 3., 4.],\n",
       "         [5., 6., 7., 8., 9.]]),\n",
       " tensor([[13.,  6.,  4.,  7.,  4.],\n",
       "         [ 5.,  7.,  9., 17., 18.]]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(10).view(2,5).float()\n",
    "b = torch.randint(0,20,(2,5)).float()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-4.4519, -3.4519, -2.4519, -1.4519, -0.4519],\n",
       "         [-4.4519, -3.4519, -2.4519, -1.4519, -0.4519]]),\n",
       " tensor([[-3.6307e-03, -7.0036e+00, -9.0036e+00, -6.0036e+00, -9.0036e+00],\n",
       "         [-1.3313e+01, -1.1313e+01, -9.3134e+00, -1.3134e+00, -3.1337e-01]]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob1 = F.log_softmax(a, dim=-1)    # pred\n",
    "log_prob2 = F.log_softmax(b, dim=-1)    # true/label\n",
    "log_prob1, log_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0519,  0.1125,  0.5643,  1.0657,  5.4424],\n",
       "        [ 0.1033,  0.2491,  0.5910, -0.0324, -0.0882]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob1.exp() * (log_prob1 - log_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.KLDivLoss(reduction='none', log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0519,  0.1125,  0.5643,  1.0657,  5.4424],\n",
       "        [ 0.1033,  0.2491,  0.5910, -0.0324, -0.0882]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(log_prob2, log_prob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86151\\AppData\\Local\\Temp\\ipykernel_9196\\4123133844.py:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = F.log_softmax(torch.randn(3, 5, requires_grad=True))\n",
      "C:\\Users\\86151\\AppData\\Local\\Temp\\ipykernel_9196\\4123133844.py:2: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  target = F.log_softmax(torch.rand(3, 5))\n"
     ]
    }
   ],
   "source": [
    "input = F.log_softmax(torch.randn(3, 5, requires_grad=True))\n",
    "target = F.log_softmax(torch.rand(3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1166,  0.0640, -0.0882,  0.1450, -0.0973],\n",
       "        [-0.0111, -0.1570,  0.2012, -0.0390,  0.2993],\n",
       "        [-0.0507,  0.0694,  0.1274,  0.0487, -0.1060]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.exp() * (target - input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1166,  0.0640, -0.0882,  0.1450, -0.0973],\n",
       "        [-0.0111, -0.1570,  0.2012, -0.0390,  0.2993],\n",
       "        [-0.0507,  0.0694,  0.1274,  0.0487, -0.1060]],\n",
       "       grad_fn=<KlDivBackward0>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1., 2., 2., 3., 3., 4., 4., 5., 5., 6., 6., 7., 7., 8., 8.,\n",
       "        9., 9.])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.flatten().repeat_interleave(2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "class child(parent):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = parent()\n",
    "c = child()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a04f5d07b0747026a8fbcdf50b9443318e69b1b8bd6247d88bfadb4789282972"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
